When you comment out the freejoint in the Humanoid model, the humanoid does not fall because you have removed all degrees of freedom (DOFs) from its root body, essentially welding it to the world coordinate system. It is "hanging" because the simulation treats it as a fixed, immovable object. 
Here's a breakdown of why this happens:
Joints define motion: In MuJoCo, bodies are organized in a kinematic tree, with the top-level body being the "worldbody". Joints are defined within a body to create motion DOFs between that body and its parent.
No joint means a weld: If no joints are defined within a given body (relative to its parent), that body is automatically welded (fixed) to its parent.
The role of freejoint: The freejoint is a special type of joint that provides 6 DOFs (3 for translation and 3 for rotation) to a body, allowing it to float and move freely in the 3D global space, subject to physics like gravity and collisions.
The "world" is the parent: The Humanoid's main body is a child of the implicit "world" body. The freejoint gives this main body the ability to move relative to the world and thus fall under gravity.
Result of commenting out: By commenting out the freejoint, the main body has no DOFs relative to the world. Therefore, it is rigidly fixed in its initial position in space, and gravity has no effect on its global position. 
To make the humanoid fall, you need to ensure its root body has the necessary degrees of freedom, which is exactly what the freejoint provides. 

----

Uncommenting the <freejoint/> means the humanoid's base body is no longer fixed to the world and will fall under gravity like a free-floating object. To prevent it from falling, you must implement an active control mechanism or modify the simulation environment. 
Simulation Environment Adjustments
The simplest immediate solutions involve changing the simulation environment settings:
Disable gravity: Set the gravity to zero in the <option> tag of the XML (e.g., <option gravity="0 0 0"/>). This will make the humanoid float in space, but it won't "fall".
Add fluid viscosity: Introduce a surrounding medium with viscosity to dampen movement and prevent the model from drifting too quickly, which can help stabilize a floating base.
Increase joint damping: Add damping to all the humanoid's internal joints in the XML to make the limbs less prone to flailing and causing instability. 
Control-Based Solutions
To have the humanoid actively maintain an upright posture and prevent falling while still under the influence of gravity (the more realistic approach), you must implement a control system:
Implement a Proportional-Derivative (PD) or PID controller: Use a controller to apply torques at the joints to maintain a desired "canonical" posture (e.g., upright with feet on the ground). This requires writing custom code in your application.
Use Residual Force Control: For complex locomotion tasks, techniques like residual force control are often used in advanced controllers (e.g., in reinforcement learning projects like UHC) to apply forces that keep the humanoid stable and balanced.
Reinforcement Learning (RL): Train an RL agent to learn balance and locomotion policies. The reward function would include terms that penalize falling, high center of mass velocity, and deviation from a balanced posture.
Center of Mass (CoM) stabilization: Design a controller that explicitly calculates the center of mass and applies forces/torques to keep the CoM projection within the support polygon (between the feet). 
The most common starting point for a stable, floating-base model is to use active control (like a PD controller) or to simply disable gravity if the goal is only to prevent "falling" in a zero-G environment.

---

Preventing a MuJoCo humanoid from falling generally involves implementing a control loop (such as a PID controller, LQR, or Model Predictive Control) or a reinforcement learning policy that continuously adjusts joint torques to maintain balance and an upright posture. A simple, direct control solution can focus on stabilizing the Center of Mass (CoM) and maintaining height. 
Below is an illustrative Python code snippet using the mujoco and numpy libraries that applies a basic proportional-derivative (PD) control to the joints, aiming to return them to a "half-sitting" or standing posture if they deviate. 
Python Code for Basic PD Control in MuJoCo
This example assumes you have a MuJoCo model loaded and are using the official mujoco Python bindings. 
python
import mujoco
import mujoco.viewer
import numpy as np

# Load the model and data (replace 'humanoid.xml' with your specific model file)
# The default humanoid model in MuJoCo can be found in the github repo or documentation
model = mujoco.MjModel.from_xml_path('humanoid.xml')
data = mujoco.MjData(model)

# Define target joint positions (a stable standing or 'half-sitting' pose)
# These values are illustrative and might need tuning for your specific XML
# The positions for the main joints can be found in the documentation or by inspecting the model.
# Example target_qpos: [root_x, root_y, root_z, root_quat_w, root_quat_x, root_quat_y, root_quat_z, *joint_positions]
# For the joints, a good starting point is the default pose or a "half-sitting" posture.
target_qpos = np.array([0, 0, 1.2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

# PD control gains (proportional and derivative)
# These are crucial for stability and need tuning
Kp = 50.0 # Proportional gain
Kd = 5.0  # Derivative gain

def apply_balance_control(model, data, target_qpos, Kp, Kd):
    """
    Applies PD control to joints to maintain a target posture and prevent falling.
    """
    # Get current joint positions and velocities
    current_qpos = data.qpos[7:] # Exclude the first 7 DOFs (free joint: pos + quat)
    current_qvel = data.qvel[6:] # Exclude the first 6 DOFs (free joint: vel + ang_vel)

    # Calculate position error
    error = target_qpos[7:] - current_qpos

    # Calculate desired control torques
    # tau = Kp * error - Kd * current_qvel (simple PD controller)
    # The control input is applied to the actuators (data.ctrl)
    data.ctrl[:] = Kp * error - Kd * current_qvel

def check_fall_condition(data):
    """
    Checks if the humanoid has fallen over (e.g., if height is below a threshold).
    """
    # The 'root' body (pelvis) height is often used as a metric for falling
    # The index for the root z-coordinate is typically 2 (after x and y)
    height = data.qpos[2]
    # A common threshold for the humanoid to be considered fallen is < 0.6m
    if height < 0.6:
        return True
    return False

# Run the simulation with the viewer
with mujoco.viewer.launch_passive(model, data) as viewer:
    # Set the initial position to a standing pose (if the XML doesn't default to it)
    data.qpos = target_qpos.copy()
    mujoco.mj_forward(model, data) # Update physics with initial state

    while viewer.is_running() and not check_fall_condition(data):
        # Apply the control solution
        apply_balance_control(model, data, target_qpos, Kp, Kd)

        # Step the simulation
        mujoco.mj_step(model, data)

        # Update viewer
        viewer.sync()

Explanation of the Control Solution
Target Posture: The target_qpos array defines the desired joint configuration for standing upright.
PD Control: A Proportional-Derivative (PD) controller is implemented in apply_balance_control. It calculates the error between the target_qpos and the current_qpos and applies a corrective torque (data.ctrl) to reduce this error and damp the velocity.
Kp * error: Proportional term, applies force proportional to the position error.
Kd * current_qvel: Derivative term, applies a damping force to prevent oscillations and overshooting.
Simulation Loop: The simulation runs step-by-step. In each step, the apply_balance_control function is called to calculate the required torques before the physics engine solves for the next state.
Fall Condition: The check_fall_condition function provides a simple check based on the height of the robot's root body to determine if the simulation should stop (i.e., if it has fallen). 
This basic approach ensures the robot attempts to return to a fixed, predefined standing posture. More advanced solutions use techniques like Reinforcement Learning (RL) or Model Predictive Control (MPC) to learn robust balance strategies or complex locomotion. 
